# AGENTS.md - Retail Data Pipeline

> File n√†y ch·ª©a th√¥ng tin h∆∞·ªõng d·∫´n d√†nh cho AI coding agents l√†m vi·ªác v·ªõi d·ª± √°n Retail Data Pipeline.
> Ng√¥n ng·ªØ ch√≠nh trong d·ª± √°n: **Ti·∫øng Vi·ªát** (t√†i li·ªáu, comments, t√™n bi·∫øn c√≥ √Ω nghƒ©a)

---

## üìã T·ªïng quan d·ª± √°n

**Retail Data Pipeline** l√† h·ªá th·ªëng data pipeline ho√†n ch·ªânh cho ng√†nh b√°n l·∫ª, bao g·ªìm:
- ETL t·ª± ƒë·ªông x·ª≠ l√Ω d·ªØ li·ªáu CSV
- Data Warehouse v·ªõi PostgreSQL (OLTP) v√† ClickHouse (OLAP)
- BI Dashboard v·ªõi Apache Superset
- ML Forecasting d·ª± b√°o b√°n h√†ng s·ª≠ d·ª•ng XGBoost

### Ki·∫øn tr√∫c h·ªá th·ªëng

```
CSV Input ‚îÄ‚îÄ‚ñ∂ PostgreSQL (OLTP) ‚îÄ‚îÄ‚ñ∂ ClickHouse (DW) ‚îÄ‚îÄ‚ñ∂ BI/Analytics
     ‚îÇ              ‚îÇ                    ‚îÇ
     ‚ñº              ‚ñº                    ‚ñº
 Data Cleaning   Transactions      Fact Tables
                 Products          Aggregations
                 Customers         Time-series
```

---

## üèóÔ∏è C·∫•u tr√∫c th∆∞ m·ª•c

```
retail_data_pipeline/
‚îú‚îÄ‚îÄ airflow/
‚îÇ   ‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ retail_pipeline_dag.py    # DAGs cho Airflow
‚îÇ   ‚îî‚îÄ‚îÄ plugins/                       # Plugins t√πy ch·ªânh
‚îú‚îÄ‚îÄ config/                            # C·∫•u h√¨nh chung
‚îú‚îÄ‚îÄ csv_input/                         # Th∆∞ m·ª•c ch·ª©a CSV c·∫ßn x·ª≠ l√Ω
‚îÇ   ‚îú‚îÄ‚îÄ processed/                     # ƒê√£ x·ª≠ l√Ω
‚îÇ   ‚îî‚îÄ‚îÄ error/                         # L·ªói
‚îú‚îÄ‚îÄ csv_output/                        # K·∫øt qu·∫£ x·ª≠ l√Ω
‚îú‚îÄ‚îÄ data_cleaning/                     # Module l√†m s·∫°ch d·ªØ li·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ auto_process_csv.py           # X·ª≠ l√Ω t·ª± ƒë·ªông
‚îÇ   ‚îú‚îÄ‚îÄ csv_processor.py              # Class l√†m s·∫°ch ch√≠nh
‚îÇ   ‚îú‚îÄ‚îÄ csv_watcher.py                # Theo d√µi file m·ªõi
‚îÇ   ‚îú‚îÄ‚îÄ db_connectors.py              # K·∫øt n·ªëi database
‚îÇ   ‚îú‚îÄ‚îÄ redis_buffer.py               # Redis cache
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ dbt_retail/                        # DBT project
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ staging/                   # L√†m s·∫°ch d·ªØ li·ªáu g·ªëc
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ intermediate/              # Transform trung gian
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ marts/                     # Facts & Dimensions
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ core/                  # dim_date, dim_product, dim_branch
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ sales/                 # fct_daily_sales, fct_monthly_sales
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ inventory/             # fct_inventory_forecast_input
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ customers/             # fct_rfm_analysis
‚îÇ   ‚îú‚îÄ‚îÄ macros/                        # H√†m ti·ªán √≠ch SQL
‚îÇ   ‚îú‚îÄ‚îÄ seeds/                         # D·ªØ li·ªáu tham chi·∫øu
‚îÇ   ‚îú‚îÄ‚îÄ tests/                         # DBT tests
‚îÇ   ‚îú‚îÄ‚îÄ dbt_project.yml               # C·∫•u h√¨nh DBT
‚îÇ   ‚îî‚îÄ‚îÄ profiles.yml                   # K·∫øt n·ªëi database
‚îú‚îÄ‚îÄ init/                              # Kh·ªüi t·∫°o database
‚îÇ   ‚îú‚îÄ‚îÄ clickhouse/
‚îÇ   ‚îî‚îÄ‚îÄ postgres/
‚îú‚îÄ‚îÄ ml_pipeline/                       # Machine Learning
‚îÇ   ‚îú‚îÄ‚îÄ xgboost_forecast.py           # D·ª± b√°o XGBoost
‚îÇ   ‚îú‚îÄ‚îÄ db_connectors.py              # K·∫øt n·ªëi DB cho ML
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ superset/                          # BI Configuration
‚îÇ   ‚îú‚îÄ‚îÄ superset_config.py
‚îÇ   ‚îú‚îÄ‚îÄ create_clickhouse_conn.py
‚îÇ   ‚îî‚îÄ‚îÄ docker-bootstrap.sh
‚îú‚îÄ‚îÄ .env                               # Environment variables
‚îú‚îÄ‚îÄ docker-compose.yml                 # ƒê·ªãnh nghƒ©a services
‚îú‚îÄ‚îÄ Makefile                          # C√°c l·ªánh th∆∞·ªùng d√πng
‚îú‚îÄ‚îÄ README.md                          # T√†i li·ªáu ng∆∞·ªù i d√πng
‚îú‚îÄ‚îÄ ARCHITECTURE.md                    # Ki·∫øn tr√∫c chi ti·∫øt
‚îî‚îÄ‚îÄ QUICK_REFERENCE.md                 # Tham kh·∫£o nhanh
```

---

## üõ†Ô∏è Technology Stack

| Layer | C√¥ng ngh·ªá | M·ª•c ƒë√≠ch |
|-------|-----------|----------|
| **Ingestion** | Python 3.11, Pandas | X·ª≠ l√Ω CSV, l√†m s·∫°ch d·ªØ li·ªáu |
| **OLTP** | PostgreSQL 15 | L∆∞u tr·ªØ giao d·ªãch th·ªùigian th·ª±c |
| **OLAP/DW** | ClickHouse 24 | Ph√¢n t√≠ch d·ªØ li·ªáu l·ªõn, time-series |
| **Cache/Buffer** | Redis 7 | T·∫°m th·ªù i, cache |
| **Transformation** | DBT 1.7 | Transform d·ªØ li·ªáu, data modeling |
| **Orchestration** | Apache Airflow 2.8 | Scheduling, workflow |
| **BI** | Apache Superset 2.1 | Dashboard, visualization |
| **ML** | XGBoost, Optuna, scikit-learn | D·ª± b√°o b√°n h√†ng + Hyperparameter tuning |
| **Container** | Docker, Docker Compose | Tri·ªÉn khai, qu·∫£n l√Ω services |

---

## üöÄ Build v√† Run Commands

### Kh·ªüi ƒë·ªông h·ªá th·ªëng (s·ª≠ d·ª•ng Makefile)

```bash
# Kh·ªüi ƒë·ªông t·∫•t c·∫£ services
make up

# Ki·ªÉm tra health
make health

# Xem status
make status

# D·ª´ng h·ªá th·ªëng
make down

# Restart
make restart
```

### X·ª≠ l√Ω d·ªØ li·ªáu CSV

```bash
# Process CSV 1 l·∫ßn (manual)
make csv-import

# Process CSV + ch·∫°y DBT transform
make csv-process-full

# X√≥a d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω
make csv-reset
```

**L∆∞u √Ω:** CSV import ƒë∆∞·ª£c schedule t·ª± ƒë·ªông trong Airflow DAG `csv_daily_import` ch·∫°y l√∫c 2h s√°ng m·ªói ng√†y.

### DBT Commands

```bash
# Run t·∫•t c·∫£ models
make dbt

# Load seed data
make dbt-seed

# Run tests
make dbt-test

# Generate v√† serve docs (port 8080)
make dbt-docs
```

### ML Pipeline

```bash
# Train models v·ªõi Optuna tuning (50 trials - default)
make ml
make ml-train

# Train nhanh (kh√¥ng tuning)
make ml-train-fast

# Train t·ªëi ∆∞u (100 trials)
make ml-train-optimal

# Train + Generate forecasts
make ml-train-predict

# Generate predictions t·ª´ model ƒë√£ train
make ml-predict
```

### Database CLI

```bash
# PostgreSQL
make psql

# ClickHouse
make clickhouse


# Redis
make redis
```

---

## üìä Service Ports

| Service | Port | M√¥ t·∫£ |
|---------|------|-------|
| PostgreSQL | 5432 | OLTP Database |
| ClickHouse HTTP | 8123 | Data Warehouse (HTTP) |
| ClickHouse Native | 9000 | Data Warehouse (Native) |
| Redis | 6379 | Buffer & Cache |
| Airflow Web | 8085 | Workflow Scheduler UI |
| Superset | 8088 | BI Dashboard |
| DBT Docs | 8080 | Documentation (khi ch·∫°y) |

---

## üîß Code Style Guidelines

### Python

- **Ti·∫øng Vi·ªát**: Comments v√† docstrings vi·∫øt b·∫±ng ti·∫øng Vi·ªát
- **Snake_case**: T√™n bi·∫øn, h√†m (`ma_giao_dich`, `tong_doanh_thu`)
- **Class names**: PascalCase (`RetailDataCleaner`, `SalesForecaster`)
- **Constants**: UPPER_CASE (`COLUMNS_SCHEMA`, `COLUMN_MAPPING`)
- **Type hints**: S·ª≠ d·ª•ng typing (`def clean(self, file_path: str) -> pd.DataFrame:`)
- **Logging**: S·ª≠ d·ª•ng module logging thay v√¨ print

### SQL (DBT)

- **Lowercase**: T·ª´ kh√≥a SQL vi·∫øt th∆∞·ªùng (`select`, `from`, `where`)
- **Snake_case**: T√™n c·ªôt, b·∫£ng
- **Ti·∫øng Vi·ªát**: T√™n c·ªôt g·ªëc t·ª´ d·ªØ li·ªáu CSV (vd: `ma_giao_dich`, `ten_hang`)
- **Models**: T·ªï ch·ª©c theo layer (`staging/`, `intermediate/`, `marts/`)
- **Tests**: Th√™m tests cho primary keys, relationships, not_null

### File Organization

```
models/
‚îú‚îÄ‚îÄ staging/           # Views, l√†m s·∫°ch c∆° b·∫£n
‚îú‚îÄ‚îÄ intermediate/      # Ephemeral, logic trung gian
‚îî‚îÄ‚îÄ marts/            # Tables, d·ªØ li·ªáu cu·ªëi c√πng
    ‚îú‚îÄ‚îÄ core/         # Dimensions
    ‚îú‚îÄ‚îÄ sales/        # Sales facts
    ‚îú‚îÄ‚îÄ inventory/    # Inventory facts
    ‚îî‚îÄ‚îÄ customers/    # Customer analytics
```

---

## üß™ Testing Strategy

### DBT Tests

C√°c tests t√≠ch h·ª£p trong `sources.yml` v√† `schema.yml`:

```yaml
columns:
  - name: id
    tests:
      - unique
      - not_null
  - name: ma_hang
    tests:
      - relationships:
          to: source('retail_source', 'products')
          field: id
```

Ch·∫°y tests:
```bash
make dbt-test
```

### Health Checks

```bash
# T·∫•t c·∫£ services
make health

# T·ª´ng service
make health-postgres
make health-clickhouse
make health-redis
make health-superset
```

---

## üîê Security Considerations

### Default Credentials (Development Only)

> ‚ö†Ô∏è **WARNING**: Thay ƒë·ªïi m·∫≠t kh·∫©u m·∫∑c ƒë·ªãnh tr∆∞·ªõc khi deploy production!

| Service | Username | Password |
|---------|----------|----------|
| PostgreSQL | retail_user | retail_password |
| ClickHouse | default | clickhouse_password |

| Airflow | admin | admin |
| Superset | admin | admin |

### Environment Variables

C√°c bi·∫øn m√¥i tr∆∞·ªùng ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a trong `.env`:

```bash
# Database connections
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=retail_db
POSTGRES_USER=retail_user
POSTGRES_PASSWORD=retail_password

# ClickHouse
CLICKHOUSE_HOST=localhost
CLICKHOUSE_PORT=9000
CLICKHOUSE_DB=retail_dw
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=clickhouse_password
```

---

## üìÅ Key Configuration Files

| File | M·ª•c ƒë√≠ch |
|------|----------|
| `docker-compose.yml` | ƒê·ªãnh nghƒ©a t·∫•t c·∫£ Docker services |
| `Makefile` | T·ª± ƒë·ªông h√≥a c√°c l·ªánh th∆∞·ªùng d√πng |
| `.env` | Bi·∫øn m√¥i tr∆∞·ªùng |
| `dbt_retail/dbt_project.yml` | C·∫•u h√¨nh DBT project |
| `dbt_retail/profiles.yml` | K·∫øt n·ªëi database cho DBT |
| `dbt_retail/packages.yml` | Dependencies DBT packages |
| `superset/superset_config.py` | C·∫•u h√¨nh Superset |

---

## üîç Debugging v√† Troubleshooting

### Xem logs

```bash
# T·∫•t c·∫£ services
make logs

# Specific service
docker-compose logs -f postgres
docker-compose logs -f clickhouse
docker-compose logs -f airflow-webserver
```

### Reset d·ªØ li·ªáu

```bash
# Reset database (gi·ªØ CSV files)
make reset-db

# Full reset (‚ö†Ô∏è x√≥a t·∫•t c·∫£ data)
make reset-all
```

### Clean Docker

```bash
make clean
# Ho·∫∑c th·ªß c√¥ng:
docker system prune -f
docker volume prune -f
```

### Common Issues

1. **Port ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng**: Ki·ªÉm tra `sudo lsof -i :5432`
2. **Container unhealthy**: `docker-compose restart <service>`
3. **DBT connection refused**: Ki·ªÉm tra `POSTGRES_HOST` environment variable
4. **Redis cache c≈©**: `docker-compose exec redis redis-cli FLUSHDB`

---

## üìù Database Schema

### PostgreSQL (OLTP)

- `branches` - Chi nh√°nh
- `products` - S·∫£n ph·∫©m
- `transactions` - Giao d·ªãch header
- `transaction_details` - Chi ti·∫øt giao d·ªãch
- `ml_forecasts` - K·∫øt qu·∫£ d·ª± b√°o ML

### ClickHouse (DW)

- `fact_transactions` - Fact table ch√≠nh
- `agg_daily_sales` - Aggregated materialized view

---

## ü§ù Development Workflow

1. **Thay ƒë·ªïi code** ‚Üí Test locally
2. **Ch·∫°y DBT** ‚Üí `make dbt`
3. **Ch·∫°y tests** ‚Üí `make dbt-test`
4. **Ki·ªÉm tra health** ‚Üí `make health`
5. **Commit changes**

---

## üìö T√†i li·ªáu tham kh·∫£o

- `README.md` - H∆∞·ªõng d·∫´n chi ti·∫øt ng∆∞·ªù i d√πng
- `ARCHITECTURE.md` - Ki·∫øn tr√∫c h·ªá th·ªëng v√† database
- `QUICK_REFERENCE.md` - Cheat sheet commands

---

---

## üîê B·∫£o M·∫≠t & Git Workflow

### .gitignore - C√°c File ƒê∆∞·ª£c B·∫£o V·ªá

| File/Pattern | L√Ω do |
|-------------|-------|
| `.env` | Ch·ª©a password, API keys |
| `csv_input/*.csv` | D·ªØ li·ªáu th√¥, kh√¥ng commit |
| `*.pkl`, `*.joblib` | ML models (l·ªõn, t√°i t·∫°o ƒë∆∞·ª£c) |
| `ml_pipeline/email_config.yaml` | Email c√° nh√¢n |
| `__pycache__/` | Python cache |
| `dbt_retail/target/` | Build artifacts |

### Push Code L√™n GitHub

```bash
# 1. Ki·ªÉm tra file thay ƒë·ªïi
git status

# 2. Xem chi ti·∫øt thay ƒë·ªïi
git diff

# 3. Add file (t·ª± ƒë·ªông ignore file trong .gitignore)
git add .

# 4. Ki·ªÉm tra l·∫°i tr∆∞·ªõc khi commit
git diff --cached --name-only

# 5. Commit
git commit -m "feat: M√¥ t·∫£ thay ƒë·ªïi"

# 6. Push (c·∫ßn c·∫•u h√¨nh token/SSH)
git push origin main
```

Xem chi ti·∫øt trong `GIT_COMMIT_GUIDE.md`

---

**Last Updated**: 2024-02-14
