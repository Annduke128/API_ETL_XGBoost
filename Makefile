# Makefile cho Retail Data Pipeline
# T·∫•t c·∫£ commands c·∫ßn thi·∫øt ƒë·ªÉ v·∫≠n h√†nh h·ªá th·ªëng

.PHONY: help up down restart logs ps clean dbt dbt-test dbt-docs \
        ml ml-train ml-predict ml-email-test ml-email-config psql clickhouse redis \
        process csv-import csv-watch csv-reset \
        health health-postgres health-clickhouse health-redis health-superset \
        reset-db reset-all status

# ============================================================================
# HELP
# ============================================================================
help:
	@echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
	@echo "‚ïë       Retail Data Pipeline - Available Commands                  ‚ïë"
	@echo "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£"
	@echo "‚ïë  DOCKER COMPOSE                                                  ‚ïë"
	@echo "‚ïë    make up              - Start all services                     ‚ïë"
	@echo "‚ïë    make down            - Stop all services                      ‚ïë"
	@echo "‚ïë    make restart         - Restart all services                   ‚ïë"
	@echo "‚ïë    make logs            - View logs (follow mode)                ‚ïë"
	@echo "‚ïë    make ps              - List running containers                ‚ïë"
	@echo "‚ïë    make status          - Check all services status              ‚ïë"
	@echo "‚ïë                                                                  ‚ïë"
	@echo "‚ïë  HEALTH CHECK                                                    ‚ïë"
	@echo "‚ïë    make health          - Check all services health              ‚ïë"
	@echo "‚ïë    make health-postgres - Check PostgreSQL                       ‚ïë"
	@echo "‚ïë    make health-clickhouse Check ClickHouse                       ‚ïë"
	@echo "‚ïë    make health-redis    - Check Redis                            ‚ïë"
	@echo "‚ïë    make health-superset - Check Superset                         ‚ïë"
	@echo "‚ïë                                                                  ‚ïë"
	@echo "‚ïë  CSV PROCESSING                                                  ‚ïë"
	@echo "‚ïë    make process         - Process CSV files in csv_input/        ‚ïë"
	@echo "‚ïë    make csv-import      - Import CSV manually                    ‚ïë"
	@echo "‚ïë    make csv-watch       - Start auto-watch mode                  ‚ïë"
	@echo "‚ïë    make csv-reset       - Clear processed/error folders          ‚ïë"
	@echo "‚ïë                                                                  ‚ïë"
	@echo "‚ïë  DBT (Data Transformation)                                       ‚ïë"
	@echo "‚ïë    make dbt             - Run all DBT models                     ‚ïë"
	@echo "‚ïë    make dbt-seed        - Load seed data                         ‚ïë"
	@echo "‚ïë    make dbt-test        - Run DBT tests                          ‚ïë"
	@echo "‚ïë    make dbt-docs        - Generate and serve DBT docs            ‚ïë"
	@echo "‚ïë                                                                  ‚ïë"
	@echo "‚ïë  ML (Machine Learning)                                           ‚ïë"
	@echo "‚ïë    make ml              - Train ML (Optuna 50 trials)            ‚ïë"
	@echo "‚ïë    make ml-train        - Train v·ªõi Optuna tuning                ‚ïë"
	@echo "‚ïë    make ml-train-fast   - Train nhanh (no tuning)                ‚ïë"
	@echo "‚ïë    make ml-train-optimal- Train t·ªëi ∆∞u (100 trials)              ‚ïë"
	@echo "‚ïë    make ml-train-predict- Train + Generate forecasts             ‚ïë"
	@echo "‚ïë    make ml-predict      - Generate predictions                   ‚ïë"
	@echo "‚ïë                                                                  ‚ïë"
	@echo "‚ïë  EMAIL NOTIFICATIONS                                             ‚ïë"
	@echo "‚ïë    make ml-email-config - Xem h∆∞·ªõng d·∫´n c·∫•u h√¨nh email           ‚ïë"
	@echo "‚ïë    make ml-email-test   - Ki·ªÉm tra c·∫•u h√¨nh email                ‚ïë"
	@echo "‚ïë    make ml-email-send-test - G·ª≠i email test                      ‚ïë"
	@echo "‚ïë                                                                  ‚ïë"
	@echo "‚ïë  DATABASE CLI                                                    ‚ïë"
	@echo "‚ïë    make psql            - Connect to PostgreSQL                  ‚ïë"
	@echo "‚ïë    make clickhouse      - Connect to ClickHouse                  ‚ïë"
	@echo "‚ïë    make redis           - Connect to Redis CLI                   ‚ïë"
	@echo "‚ïë                                                                  ‚ïë"
	@echo "‚ïë  MAINTENANCE                                                     ‚ïë"
	@echo "‚ïë    make reset-db        - Reset database (keep CSV files)        ‚ïë"
	@echo "‚ïë    make reset-all       - Full reset (‚ö†Ô∏è  destroys all data)     ‚ïë"
	@echo "‚ïë    make clean           - Clean Docker cache and volumes         ‚ïë"
	@echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"

# ============================================================================
# DOCKER COMPOSE COMMANDS
# ============================================================================

# Kh·ªüi ƒë·ªông t·∫•t c·∫£ services
up:
	@echo "üöÄ Starting all services..."
	docker-compose up -d postgres clickhouse redis
	@sleep 30
	docker-compose up -d airflow-init airflow-webserver airflow-scheduler
	docker-compose up -d superset-init superset-web
	@echo "‚è≥ Waiting for services to be healthy (60s)..."
	@sleep 60
	@echo "‚úÖ All services started!"
	@docker-compose ps

# D·ª´ng t·∫•t c·∫£ services
down:
	@echo "üõë Stopping all services..."
	docker-compose down

# Restart services
restart:
	@echo "üîÑ Restarting services..."
	docker-compose restart

# Xem logs
logs:
	docker-compose logs -f

# Li·ªát k√™ containers
ps:
	docker-compose ps

# Ki·ªÉm tra status
status:
	@echo "üìä Services Status:"
	@docker-compose ps --format "table {{.Name}}\t{{.Status}}\t{{.Ports}}"

# ============================================================================
# HEALTH CHECK
# ============================================================================

health: health-postgres health-clickhouse health-redis health-superset

health-postgres:
	@echo "üîç Checking PostgreSQL..."
	@docker-compose exec -T postgres pg_isready -U retail_user -d retail_db && echo "‚úÖ PostgreSQL is healthy" || echo "‚ùå PostgreSQL failed"

health-clickhouse:
	@echo "üîç Checking ClickHouse..."
	@docker-compose exec -T clickhouse clickhouse-client -q "SELECT 'OK'" && echo "‚úÖ ClickHouse is healthy" || echo "‚ùå ClickHouse failed"

health-redis:
	@echo "üîç Checking Redis..."
	@docker-compose exec -T redis redis-cli ping && echo "‚úÖ Redis is healthy" || echo "‚ùå Redis failed"

health-superset:
	@echo "üîç Checking Superset..."
	@curl -s -o /dev/null -w "%{http_code}" http://localhost:8088/health | grep -q "200" && echo "‚úÖ Superset is healthy" || echo "‚ùå Superset failed"

# ============================================================================
# CSV PROCESSING
# ============================================================================

# X·ª≠ l√Ω CSV m·ªôt l·∫ßn
process: csv-import

csv-import:
	@echo "üìÅ Processing CSV files..."
	docker-compose run --rm \
		-v "$(PWD)/csv_input:/csv_input" \
		-v "$(PWD)/csv_output:/csv_output" \
		csv-watcher \
		python auto_process_csv.py --input /csv_input --output /csv_output

# Trigger CSV import manually (ch·∫°y 1 l·∫ßn)
csv-import:
	@echo "üìÅ Processing CSV files..."
	docker-compose --profile watcher run --rm csv-watcher python auto_process_csv.py

# Ch·∫°y CSV import + DBT transform (gi·ªëng Airflow DAG)
csv-process-full: csv-import dbt
	@echo "‚úÖ CSV processing and DBT transform completed"

# X√≥a d·ªØ li·ªáu processed/error
csv-reset:
	@echo "üßπ Resetting CSV folders..."
	@docker run --rm -v "$(PWD)/csv_input:/csv" alpine sh -c \
		"rm -rf /csv/processed/* /csv/error/* 2>/dev/null; echo 'Done'"

# ============================================================================
# DBT COMMANDS
# ============================================================================

# Environment variables cho DBT
DBT_ENV := -e POSTGRES_HOST=postgres \
		   -e POSTGRES_PORT=5432 \
		   -e POSTGRES_USER=retail_user \
		   -e POSTGRES_PASSWORD=retail_password \
		   -e POSTGRES_DB=retail_db

# Ch·∫°y t·∫•t c·∫£ models
dbt:
	@echo "üîß Running DBT models..."
	docker-compose run --rm $(DBT_ENV) dbt deps
	docker-compose run --rm $(DBT_ENV) dbt seed
	docker-compose run --rm $(DBT_ENV) dbt run

# Load seed data
dbt-seed:
	@echo "üå± Loading DBT seeds..."
	docker-compose run --rm $(DBT_ENV) dbt seed

# Ch·∫°y tests
dbt-test:
	@echo "üß™ Running DBT tests..."
	docker-compose run --rm $(DBT_ENV) dbt test

# Generate v√† serve docs
dbt-docs:
	@echo "üìö Generating DBT docs..."
	docker-compose run --rm $(DBT_ENV) dbt docs generate
	@echo "üìñ Starting docs server at http://localhost:8080"
	docker-compose run --rm $(DBT_ENV) -p 8080:8080 dbt docs serve --host 0.0.0.0 --port 8080

# Full DBT workflow
dbt-full: dbt-seed dbt dbt-test
	@echo "‚úÖ DBT full workflow completed!"

# ============================================================================
# ML COMMANDS
# ============================================================================

# Train ML models v·ªõi Optuna tuning (default)
ml: ml-train

ml-train:
	@echo "ü§ñ Training ML models v·ªõi Optuna tuning..."
	docker-compose --profile ml run --rm ml-pipeline python train_models.py --trials 50

# Train nhanh (kh√¥ng tuning)
ml-train-fast:
	@echo "‚ö° Training ML models (no tuning)..."
	docker-compose --profile ml run --rm ml-pipeline python train_models.py --no-tuning

# Train v·ªõi nhi·ªÅu trials (t·ªëi ∆∞u h∆°n, l√¢u h∆°n)
ml-train-optimal:
	@echo "üéØ Training ML models v·ªõi 100 trials..."
	docker-compose --profile ml run --rm ml-pipeline python train_models.py --trials 100

# Train + Predict
ml-train-predict:
	@echo "ü§ñ Training + Generating forecasts..."
	docker-compose --profile ml run --rm ml-pipeline python train_models.py --trials 50 --predict

# Train + Predict kh√¥ng g·ª≠i email
ml-train-predict-no-email:
	@echo "ü§ñ Training + Generating forecasts (no email)..."
	docker-compose --profile ml run --rm ml-pipeline python train_models.py --trials 50 --predict --no-email

# Generate predictions t·ª´ model ƒë√£ train
ml-predict:
	@echo "üìà Generating predictions..."
	docker-compose --profile ml run --rm ml-pipeline python -c \
		"from xgboost_forecast import SalesForecaster; f = SalesForecaster(); p = f.predict_next_week(); f.save_forecasts(p)"

# ============================================================================
# DATABASE CLI
# ============================================================================

# PostgreSQL CLI
psql:
	docker-compose exec postgres psql -U retail_user -d retail_db

# ClickHouse CLI
clickhouse:
	docker-compose exec clickhouse clickhouse-client

# Redis CLI
redis:
	docker-compose exec redis redis-cli

# ============================================================================
# MAINTENANCE
# ============================================================================

# Reset database (x√≥a d·ªØ li·ªáu nh∆∞ng gi·ªØ files)
reset-db:
	@echo "‚ö†Ô∏è  Resetting databases..."
	@docker-compose exec -T postgres psql -U retail_user -d retail_db -c \
		"TRUNCATE TABLE transaction_details, transactions, products, branches, ml_forecasts RESTART IDENTITY CASCADE;" 2>/dev/null || true
	@docker-compose exec -T clickhouse clickhouse-client -q "TRUNCATE TABLE retail_dw.fact_transactions" 2>/dev/null || true
	@docker-compose exec redis redis-cli FLUSHDB 2>/dev/null || true
	@echo "‚úÖ Databases reset!"

# Full reset (‚ö†Ô∏è destructive)
reset-all: down
	@echo "‚ö†Ô∏è  Full reset - destroying all data..."
	docker-compose down -v
	docker system prune -f
	@echo "‚úÖ System fully reset! Run 'make up' to start fresh."

# Clean Docker cache
clean:
	@echo "üßπ Cleaning Docker cache..."
	docker system prune -f
	docker volume prune -f

# View disk usage
disk:
	docker system df

# ============================================================================
# EMAIL NOTIFICATION COMMANDS
# ============================================================================

# Ki·ªÉm tra c·∫•u h√¨nh email
ml-email-test:
	@echo "üìß Testing email configuration..."
	docker-compose --profile ml run --rm ml-pipeline python test_email.py

# G·ª≠i email test
ml-email-send-test:
	@echo "üì§ Sending test email..."
	docker-compose --profile ml run --rm ml-pipeline python test_email.py --send-test

# M·ªü file c·∫•u h√¨nh email ƒë·ªÉ ch·ªânh s·ª≠a
ml-email-config:
	@echo "üìù Opening email configuration file..."
	@echo "File location: ml_pipeline/email_config.yaml"
	@echo ""
	@echo "üìã H∆∞·ªõng d·∫´n c·∫•u h√¨nh:"
	@echo "   1. Thay ƒë·ªïi 'primary' email th√†nh email c·ªßa b·∫°n"
	@echo "   2. Th√™m email ph·ª• trong 'additional' (t√πy ch·ªçn)"
	@echo "   3. B·∫≠t/t·∫Øt c√°c lo·∫°i th√¥ng b√°o trong 'notifications'"
	@echo "   4. Ki·ªÉm tra c·∫•u h√¨nh SMTP (server, port)"
	@echo ""
	@echo "üîê Thi·∫øt l·∫≠p Gmail App Password:"
	@echo "   1. B·∫≠t 2-Factor Authentication trong Google Account"
	@echo "   2. Truy c·∫≠p: https://myaccount.google.com/apppasswords"
	@echo "   3. T·∫°o App Password cho 'Mail' > 'Other (Custom name)'"
	@echo "   4. Copy 16 k√Ω t·ª± v√†o .env ho·∫∑c bi·∫øn m√¥i tr∆∞·ªùng EMAIL_PASSWORD"
	@echo ""
	@echo "‚úÖ Sau khi c·∫•u h√¨nh xong, test v·ªõi: make ml-email-send-test"
